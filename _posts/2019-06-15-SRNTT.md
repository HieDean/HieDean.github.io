---
layout:     post
title:      "Image Super-Resolution by Neural Texture Transfer 论文解读 "
subtitle:   ""
date:       2019-6-15
author:     "HieDean"
header-img: "img/bg.jpg"
tags:
    - CVPR2019
    - python
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
### 论文内容概述
##### SR问题的两个研究方向
SR**(super resolution)**一般指图像超分辨率，目前的研究有两种方案，一种是比较传统的单图超分辨率另一种是基于参考图像的超分辨率。

单图超分辨率模型**(SISR)**的输入只有一张图象，模型会从这一张图像提取一些高频信息并使用特殊的方法合成到原图上去，以完成超分辨率的过程。这种方法有一个缺点，模糊图像毕竟不含有我们想要的高频信息，所以即便我们使用特殊的方法去提取，最后得到的结果也不可能与实际情况完全相同，也就是说，最后模型得到的图像存在一些虚假的纹理，虽然在视觉效果上图像是清晰的，但是图像的细节信息却是假的。

为了解决单图超分辨率的缺点，另一种方案被提了出来，这就是基于参考图像的超分辨率**(RefSR)**。这种模型的输入图像有两个，一个是模糊图像，一个是清晰图像。模型会从清晰图像中提取真实的高频信息，然后将其合成到模糊图像中去。也许你会有一个疑问，既然已经有了清晰的图像，为什么我们去做超分辨率？这是因为清晰图像的角度、拍摄内容、光线等不一定乐意是我们满意，但它的高频信息却是我们需要的。

##### SRNTT做出的贡献
现有的RefSP模型对参考图像有很高的要求，要求参考图像与模糊图像的内容相仿且具有良好的对齐，这是比较难做到的，后来有人提出使用optical flow(一种图像对齐算法)先对参考图像和模糊图像进行对齐，然后送入RefSR模型。但是optical flow在两张图象的错位极其严重时表现欠佳，因此Adobe团队提出了基于纹理迁移的图像超分辨率模型**(Image Super-Resolution by Neural Texture Transfer)**，简称为SRNTT。
SRNTT主要有以下几个贡献：
* 解决了现有SISR方法会出现虚假纹理的问题
* 放松了现有的RefSR方法的约束问题，不要求参考图像与模糊图像严格对齐
* 提高了现有RefSR方法的鲁棒性，即使使用相似性不是很高的参考图像也可以得到较好的结果
* 构建了一个基准数据集CUFED5

###### 网络结构
![](/img/SRNTT/structure.jpg)
SRNTT主要由两个部分组成，一是上图中蓝色方框之外的部分，称之为特征交换；另一部分为蓝色方框内部的纹理迁移部分。

为什么SRNTT可以做到不用对齐也不需要相似度太高就能将参考图像的纹理信息传送给SR图呢？ 

其特点就在于特征交换和纹理转换这两部分都是在特征空间进行的，不是在原图上进行的。

1. 特征交换
  特征交换就是将低分辨率图像的众多特征与参考图像的众多特征进行匹配，然后提取出能够使用的合理的特征图，然后通过纹理转换部分将提取出的特征图与低分辨率的特征图合并，最终得到SR图像。
  特征交换流程如下
  ![](/img/SRNTT/structure_2.png)
  将模糊图像的上采样图像、参考图像、参考图像的下上采样图像，三张图像分别送入VGG19网络，并取出VGG的Relu1_1、Relu2_1、Relu3_1这三层输出的特征图。
  对模糊图像的上采样图像和参考图像的下上采样图像的特征图，SRNTT会使用下面的公式计算这两个特征图之间的相似性

  $$S_{i,j}=<P_i(\phi (I^{LR\uparrow})),\frac{P_j(\phi (I^{Ref\downarrow \uparrow}))}{||P_j(\phi (I^{Ref\downarrow \uparrow}))||}>$$

  该公式计算了**正则化后的参考图像的下上采样图像的特征图**与**模糊图像的上采样图像的特征图**的内积，并把结果定义为了两张特征图的相似性。但这种一张一张计算的方式很费时间，所以采用了下面这个公式

  $$S_j=\phi (I^{LR\uparrow})*\frac{P_j(\phi (I^{Ref\downarrow \uparrow}))}{||P_j(\phi (I^{Ref\downarrow \uparrow}))||}$$

  得到了每张特征图之间的相似性之后，对每张**模糊图像的上采样图像的特征图**，我们将与它最相似的特征图所对应的那个**参考图像的特征图**一起拿出来组成$M$，也就是下面这个公式的操作**(注意$I^{Ref}$和$I^{Ref\downarrow\uparrow}$是有区别的)**

  $$P_{\omega (x,y)}(M)=P_{j^*}(\phi (I^{Ref})),j^*=arg maxS_j(x,y)$$

2. 纹理迁移
  原始模糊图像首先会经过一个残差模块被转入到特征空间，然后和特征交换模块得到的$M$进行特征合并，合并后的特征图又会经过一个残差模块被放大2倍，这个步骤会进行3次，只不过最后一次不会放大2倍，而是直接输出的超分辨率图像。
  ![](/img/SRNTT/structure_3.png)
  特征合并后经过残差模块并放大

  $$\psi_l=[Res(\psi_{l-1}||M_{l-1})+\psi_{l-1}]\uparrow _{2\times}$$
  最后一次不放大得到输出结果

  $$I^{SR}=Res(\psi_{L-1}||M_{L-1})+\psi_{L-1}$$

3. loss function
  SRNTT采用了下面四种损失函数，并企图优化它们最终的加权和
* Reconstruction loss用于维持结构的相似性

  $$L_{rec}=||I^{HR}-I^{SR}||_1$$

* Perceptual loss和Adversarial loss用于提高视觉效果

  $$\mathcal{L}_{per}=\frac{1}{V}\sum\limits_{i=1}^{C}||\phi_i(I^{HR})-\phi_i(I^{SR})||_F$$

  $$\mathcal{L}_{adv}=-\mathbb{E}_{\tilde{x}\sim \mathbb{P}_g}[D(\tilde{x})]$$

  $$\mathop{min}\limits_{G} \mathop{max}\limits_{D\in\mathcal{D}}\mathbb{E}_{x\sim \mathbb{P}_r}[D(x)]-\mathbb{E}_{\tilde{x}\sim \mathbb{P}_g}[D(\tilde{x})]$$

* Texture loss用于保证纹理的真实性，以防生成虚假纹理

  $$\mathcal{L}_{tex}=\sum\limits_{l}\lambda_l||G_r(\psi_l(I^{SR})\cdot S_l^*)-G_r(M_l\cdot S_l^*)||_F$$

###### 主要结果
论文对比了不同的模型在不同数据集上的表现，最后结果是，定量观测PSNR值来看，在单图超分辨率领域，SRNTT取得第二名；在基于参考的超分辨领域，SRNTT优于现有的所有模型，位列第一。
![](/img/SRNTT/res_compare.png)

### 主要问题
##### 如何合并特征图？
论文中在讨论纹理转换的时候提到了特征图的合并，但却没有给出具体的合并方法。通过阅读代码看到这一部分主要是采用了反卷积的思想。

##### 如何实现单图超分辨率？
从对比结果来看，SRNTT模型在SISR问题上的表现也是相当不错的，但是是如何实现的，论文中却并没有提及。从代码来看，SRNTT的SISR部分也是有着较大的工程量，用到了很多的残差模块，对于这些模块的解释以及理论分析，论文描述甚少，我们无从得知。

##### 模糊图像的来源？
SRNTT的模糊图像是通过一个清晰图像经过下采样得到的，这种图像显然与真实的模糊图像是有区别的。

##### 关于参考图相似度的问题真的解决了吗？
在实际实验中，我们发现当两张输入图片的相似度很低时，输出结果在视觉效果上并不是很理想，即便两张图片的内容只是同一物体的不同角度。

### 改进方案
##### 构建含有真实的模糊图像的数据集，并训练。
构建数据集往往是深度学习工作量最大的一部份，构建构建含有真实的模糊图像的数据集意味着在拍摄时，要拍三张图片，一张清晰、一张模糊、一张用于参考，除此之外，后期打标签的工作量更是加剧。
##### 使用网络进行上下采样。
SRNTT模型中对参考图像进行下上采样主要是为了进行模糊化处理，这样可以更好地提取图像的结构信息。个人认为这一部分或许也可以采用一个轻量级的网络去实现。
##### 对高频信息进行3D重构。
在实验中发现，输出结果常常因为参考图像与模糊图像角度不同而差距很大，或许我们可以利用现有的3D重构的模型，对参考图像的特征图进行3D重构得到一个和模糊图像角度相差不大的特征图，再去做纹理迁移。
### 参考文章
[https://blog.csdn.net/wangchy29/article/details/88566724](https://blog.csdn.net/wangchy29/article/details/88566724)
[https://www.cnblogs.com/wxl845235800/p/10595230.html](https://www.cnblogs.com/wxl845235800/p/10595230.html)
[http://211.81.63.2/cache/8/03/web.eecs.utk.edu/c076c3d99b8c6a412a8672b8e0ff020a/cvpr2019_final.pdf](http://211.81.63.2/cache/8/03/web.eecs.utk.edu/c076c3d99b8c6a412a8672b8e0ff020a/cvpr2019_final.pdf)
